{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominykas.seputis/github/fomo/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fomo.models.clip.clip_base import ClipBase\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP Base Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = ClipBase()\n",
    "clip.to_cpu()\n",
    "clip.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.precompute_prompt_features([\"a picture of a cat\", \"a picture of kitten\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"./cat.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = clip.transform(img).view(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[29.0192, 26.0525]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = clip.forward(img_tensor)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9510, 0.0490]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.functional.F.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fomo.utils.data.datasets import DatasetInitializer\n",
    "from fomo.utils.data import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "# loading zero_shot_dataset\n",
    "zero_shot_dataset = DatasetInitializer.from_str(\"cifar10\").value(train=True)\n",
    "\n",
    "# zero_shot_dataset contains two properties: torch dataset and labels\n",
    "print(zero_shot_dataset.dataset)\n",
    "print(zero_shot_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 10000\n"
     ]
    }
   ],
   "source": [
    "# you can also split the dataset into train and eval splits using utils\n",
    "\n",
    "# using percentage split\n",
    "train_dataset, val_dataset = utils.split_train_val(zero_shot_dataset.dataset, train_size=0.8)\n",
    "print(len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 20\n"
     ]
    }
   ],
   "source": [
    "# using number of samples split\n",
    "\n",
    "train_dataset, val_dataset = utils.split_train_val(zero_shot_dataset.dataset, train_eval_samples=[10, 20])\n",
    "print(len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "# using subsample split\n",
    "subsampled_dataset = utils.subsample_classes(zero_shot_dataset.dataset, \"all\")\n",
    "print(subsampled_dataset.__len__())\n",
    "\n",
    "subsampled_dataset = utils.subsample_classes(zero_shot_dataset.dataset, \"base\")\n",
    "print(subsampled_dataset.__len__())\n",
    "\n",
    "subsampled_dataset = utils.subsample_classes(zero_shot_dataset.dataset, \"new\")\n",
    "print(subsampled_dataset.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominykas.seputis/github/fomo/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fomo.pipelines.train import Learner\n",
    "from fomo.pipelines.types.learner_args import LearnerArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Turning off gradients in both the image and the text encoder\n",
      "Parameters to be updated: {'image_linear.0.weight', 'image_linear.0.bias'}\n",
      "Number of learnable paramms: 262656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominykas.seputis/github/fomo/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "learner_args = LearnerArgs()\n",
    "learner_args.device = \"cpu\"\n",
    "learner_args.epochs = 1\n",
    "learner_args.model_type = \"clip_linear\"\n",
    "learner_args.use_wandb = True\n",
    "learner_args.train_subsample = \"base\"\n",
    "learner_args.test_subsample = \"new\"\n",
    "learner_args.train_eval_size = (10, 10)\n",
    "\n",
    "learner = Learner(learner_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdqmiss\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dominykas.seputis/github/fomo/notebooks/wandb/run-20240523_204300-jg2w49pr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dqmiss/fomo/runs/jg2w49pr' target=\"_blank\">clip_base_vit-b16_1716489699</a></strong> to <a href='https://wandb.ai/dqmiss/fomo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dqmiss/fomo' target=\"_blank\">https://wandb.ai/dqmiss/fomo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dqmiss/fomo/runs/jg2w49pr' target=\"_blank\">https://wandb.ai/dqmiss/fomo/runs/jg2w49pr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1]\tTime 11.054 (11.054)\tData 10.446 (10.446)\tLoss 2.6379e+00 (2.6379e+00)\tAcc@1   0.00 (  0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:17<00:00, 17.17s/it]\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [0/1]\tTime 10.451 (10.451)\tLoss 1.8925e+00 (1.8925e+00)\tPrompt Acc@1  20.00 ( 20.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prompt Acc@1 20.000\n",
      "saved best file\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/157 [00:11<30:40, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [  0/157]\tTime 11.799 (11.799)\tLoss 2.5814e+00 (2.5814e+00)\tPrompt Acc@1   9.38 (  9.38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/157 [00:46<08:40,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [ 10/157]\tTime  3.714 ( 4.184)\tLoss 2.5792e+00 (2.4580e+00)\tPrompt Acc@1   7.81 ( 10.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 21/157 [01:19<07:32,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [ 20/157]\tTime  3.238 ( 3.795)\tLoss 2.4487e+00 (2.4532e+00)\tPrompt Acc@1   9.38 ( 10.49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 31/157 [01:52<06:54,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [ 30/157]\tTime  3.239 ( 3.638)\tLoss 2.5285e+00 (2.4703e+00)\tPrompt Acc@1   9.38 (  9.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 41/157 [02:25<06:23,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [ 40/157]\tTime  3.341 ( 3.560)\tLoss 2.5206e+00 (2.4615e+00)\tPrompt Acc@1  12.50 ( 10.02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 51/157 [03:00<06:01,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [ 50/157]\tTime  3.375 ( 3.536)\tLoss 2.6653e+00 (2.4694e+00)\tPrompt Acc@1   9.38 (  9.99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 61/157 [03:33<05:20,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [ 60/157]\tTime  3.338 ( 3.506)\tLoss 2.4688e+00 (2.4721e+00)\tPrompt Acc@1   7.81 (  9.84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 71/157 [04:07<04:48,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [ 70/157]\tTime  3.312 ( 3.482)\tLoss 2.5490e+00 (2.4694e+00)\tPrompt Acc@1   7.81 (  9.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 81/157 [04:40<04:11,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [ 80/157]\tTime  3.228 ( 3.466)\tLoss 2.4381e+00 (2.4770e+00)\tPrompt Acc@1  10.94 (  9.82)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 91/157 [05:14<03:42,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [ 90/157]\tTime  3.420 ( 3.461)\tLoss 2.4622e+00 (2.4848e+00)\tPrompt Acc@1  12.50 (  9.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 101/157 [05:48<03:06,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [100/157]\tTime  3.279 ( 3.449)\tLoss 2.3963e+00 (2.4881e+00)\tPrompt Acc@1  12.50 (  9.99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 111/157 [06:21<02:32,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [110/157]\tTime  3.291 ( 3.438)\tLoss 2.4520e+00 (2.4841e+00)\tPrompt Acc@1   7.81 ( 10.08)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 121/157 [06:54<01:58,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [120/157]\tTime  3.280 ( 3.429)\tLoss 2.3733e+00 (2.4836e+00)\tPrompt Acc@1  18.75 ( 10.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 131/157 [07:28<01:26,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [130/157]\tTime  3.369 ( 3.422)\tLoss 2.6873e+00 (2.4849e+00)\tPrompt Acc@1   4.69 (  9.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 141/157 [08:02<00:54,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [140/157]\tTime  3.443 ( 3.420)\tLoss 2.3139e+00 (2.4820e+00)\tPrompt Acc@1  15.62 (  9.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 151/157 [08:35<00:19,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [150/157]\tTime  3.193 ( 3.413)\tLoss 2.3879e+00 (2.4802e+00)\tPrompt Acc@1   9.38 (  9.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [09:13<00:00,  3.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prompt Acc@1 10.040\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/79 [00:11<15:01, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [ 0/79]\tTime 11.553 (11.553)\tLoss 1.9260e+00 (1.9260e+00)\tPrompt Acc@1  20.31 ( 20.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/79 [00:45<03:54,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [10/79]\tTime  3.283 ( 4.146)\tLoss 1.9104e+00 (1.8901e+00)\tPrompt Acc@1  14.06 ( 20.60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 21/79 [01:19<03:17,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [20/79]\tTime  3.359 ( 3.784)\tLoss 1.9115e+00 (1.8893e+00)\tPrompt Acc@1  20.31 ( 20.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 31/79 [01:53<02:42,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [30/79]\tTime  3.381 ( 3.654)\tLoss 1.9061e+00 (1.9018e+00)\tPrompt Acc@1  15.62 ( 19.56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 41/79 [02:26<02:07,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [40/79]\tTime  3.471 ( 3.577)\tLoss 2.0188e+00 (1.9094e+00)\tPrompt Acc@1  20.31 ( 19.63)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 51/79 [03:00<01:35,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [50/79]\tTime  3.448 ( 3.540)\tLoss 1.9069e+00 (1.9186e+00)\tPrompt Acc@1  21.88 ( 19.94)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 61/79 [03:34<01:00,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [60/79]\tTime  3.301 ( 3.515)\tLoss 1.6355e+00 (1.9096e+00)\tPrompt Acc@1  28.12 ( 19.98)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 71/79 [04:07<00:26,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [70/79]\tTime  3.310 ( 3.491)\tLoss 1.6977e+00 (1.9096e+00)\tPrompt Acc@1  26.56 ( 19.83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [04:51<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prompt Acc@1 20.080\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/79 [00:11<15:27, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [ 0/79]\tTime 11.888 (11.888)\tLoss 1.6161e+00 (1.6161e+00)\tPrompt Acc@1  25.00 ( 25.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/79 [00:46<03:55,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [10/79]\tTime  3.369 ( 4.197)\tLoss 1.5206e+00 (1.6149e+00)\tPrompt Acc@1  40.62 ( 27.98)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 21/79 [01:19<03:14,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [20/79]\tTime  3.240 ( 3.805)\tLoss 1.6797e+00 (1.6312e+00)\tPrompt Acc@1  25.00 ( 26.86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 31/79 [01:53<02:40,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [30/79]\tTime  3.237 ( 3.660)\tLoss 1.6802e+00 (1.6406e+00)\tPrompt Acc@1  23.44 ( 25.71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 41/79 [02:27<02:09,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [40/79]\tTime  3.443 ( 3.591)\tLoss 1.6760e+00 (1.6457e+00)\tPrompt Acc@1  17.19 ( 25.04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 51/79 [03:00<01:34,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [50/79]\tTime  3.477 ( 3.538)\tLoss 1.6201e+00 (1.6538e+00)\tPrompt Acc@1  32.81 ( 24.69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 61/79 [03:34<01:01,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [60/79]\tTime  3.536 ( 3.518)\tLoss 1.6810e+00 (1.6547e+00)\tPrompt Acc@1  18.75 ( 24.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 71/79 [04:08<00:27,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: [70/79]\tTime  3.356 ( 3.506)\tLoss 1.5504e+00 (1.6482e+00)\tPrompt Acc@1  32.81 ( 25.13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [04:53<00:00,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prompt Acc@1 24.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending ClipBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ClipBase\n",
    "from fomo.models.clip.clip_base import ClipBase\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipExtension(ClipBase):\n",
    "    def __init__(self, backbone: str = \"ViT-B/16\", root: str = \"./data\") -> None:\n",
    "        # pass default arguments to the parent class\n",
    "        super(ClipExtension, self).__init__(backbone, root=root)\n",
    "\n",
    "        # add additional blocks to the model\n",
    "\n",
    "        self.visual_mlp = nn.Sequential(\n",
    "            nn.Linear(self._clip.visual.output_dim, 12),\n",
    "            nn.Linear(12, self._clip.visual.output_dim)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def learnable_param_names(self) -> set[str]:\n",
    "         # IMPORTANT: Add the name of the learnable parameters in the model\n",
    "        return set([\"image_linear\"])\n",
    "\n",
    "    # If needed you can override the to_cpu and to_cuda methods\n",
    "    def to_cpu(self) -> None:\n",
    "        self._clip.to(torch.device(\"cpu\"))\n",
    "        self.image_linear.to(torch.device(\"cpu\"))\n",
    "        self._clip.float()\n",
    "\n",
    "    def to_cuda(self) -> None:\n",
    "        self.image_linear.to(torch.device(\"cuda\"))\n",
    "        self._clip.to(torch.device(\"cuda\"))\n",
    "\n",
    "    def forward(self, images: torch.Tensor, prompts: list[str] | None = None) -> torch.Tensor:\n",
    "        # Change the forward method to include the visual_mlp\n",
    "        if prompts:\n",
    "            text_features = self.encode_text(prompts)\n",
    "        elif self._precomputed_prompt_features is not None:\n",
    "            text_features = self._precomputed_prompt_features\n",
    "        else:\n",
    "            raise ValueError(\"At least one prompts or pre-computed promt features has to be present.\")\n",
    "\n",
    "        image_features = self.encode_images(images)\n",
    "\n",
    "        image_features = self.image_linear(image_features)\n",
    "\n",
    "        logits_per_image: torch.Tensor = self.logit_scale * image_features @ text_features.t()\n",
    "\n",
    "        return logits_per_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_linear'}\n"
     ]
    }
   ],
   "source": [
    "model = ClipExtension()\n",
    "\n",
    "#print learnable parameters\n",
    "print(model.learnable_param_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
